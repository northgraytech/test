<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>ğŸ™ï¸ Meeting Transcriber</title>
<style>
body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background-color:#f0f4f8; margin:0; padding:0; text-align:center; color:#2c3e50;}
header { background-color:#34495e; color:#ecf0f1; padding:25px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
header h1 { margin:0; color:#4fc3f7; font-size: 2.5em; }
section { padding:30px 20px; }
.controls { margin: 20px auto; max-width: 600px; display: flex; justify-content: space-around; }
button { padding:12px 24px; font-size:16px; border:none; border-radius:30px; cursor:pointer; transition: background-color 0.3s, transform 0.1s; font-weight: bold; min-width: 150px; }
button:hover { transform: translateY(-2px); box-shadow: 0 4px 8px rgba(0,0,0,0.2); }
button:disabled { opacity: 0.6; cursor: not-allowed; transform: none; box-shadow: none; }

#startBtn { background-color:#2ecc71; color:#fff; } /* Green for Go */
#startBtn:hover:not(:disabled) { background-color: #27ae60; }
#stopBtn { background-color:#e74c3c; color:#fff; } /* Red for Stop */
#stopBtn:hover:not(:disabled) { background-color: #c0392b; }
#downloadBtn { background-color:#3498db; color:#fff; } /* Blue for Action */
#downloadBtn:hover:not(:disabled) { background-color: #2980b9; }

#status { margin-top: 15px; font-size: 1.1em; color: #f39c12; min-height: 20px; }
#transcript { width:90%; max-width:800px; margin:20px auto; padding:20px; border:1px solid #bdc3c7; min-height:300px; overflow-y:auto; background-color:#ffffff; color:#2c3e50; text-align: left; line-height: 1.6; border-radius: 8px; box-shadow: inset 0 2px 4px rgba(0,0,0,0.05); white-space: pre-wrap;}
</style>
</head>
<body>
<header>
Â  <h1>ğŸ™ï¸ Live Meeting Transcriber</h1>
</header>
<section>
Â  <p>Use the **Start Recording** button to begin transcription. The recognized speech will appear below.</p>
Â  <div class="controls">
Â  Â  <button id="startBtn">Start Recording</button>
Â  Â  <button id="stopBtn" disabled>Stop Recording</button>
Â  Â  <button id="downloadBtn" disabled>Download Transcript</button>
Â  </div>
Â  <div id="status">Ready to start.</div>
Â  <div id="transcript"></div>
</section>

<script>
let recognition = null;
let listening = false;
let transcriptText = ''; // Stores the final, confirmed transcript
const transcriptDiv = document.getElementById('transcript');
const statusDiv = document.getElementById('status');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const downloadBtn = document.getElementById('downloadBtn');

// --- Helper Functions ---

function updateStatus(message, color = '#f39c12') {
Â  statusDiv.innerText = message;
Â  statusDiv.style.color = color;
}

function updateButtons(isListening) {
Â  startBtn.disabled = isListening;
Â  stopBtn.disabled = !isListening;
Â  downloadBtn.disabled = isListening || transcriptText.trim().length === 0;
}

// --- Speech Recognition Core ---

function initializeRecognition() {
Â  // Check for browser compatibility (using vendor prefixes for wider support)
Â  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

Â  if (!SpeechRecognition) {
Â  Â  updateStatus('âŒ Browser Error: Web Speech API not supported. Try Chrome or Edge.', '#e74c3c');
Â  Â  return null;
Â  }
Â  
Â  const recog = new SpeechRecognition();
Â  recog.continuous = true; // Keep listening even after a pause
Â  recog.interimResults = true; // Show results as they come in (live preview)
Â  recog.lang = 'en-US'; // Set a default language

Â  // Event fired when speech is recognized
Â  recog.onresult = (event) => {
Â  Â  let interim = '';
Â  Â  let final = '';

Â  Â  for (let i = event.resultIndex; i < event.results.length; ++i) {
Â  Â  Â  const result = event.results[i];
Â  Â  Â  if (result.isFinal) {
Â  Â  Â  Â  final += result[0].transcript + '. \n'; // Add punctuation and newline
Â  Â  Â  } else {
Â  Â  Â  Â  interim += result[0].transcript;
Â  Â  Â  }
Â  Â  }

Â  Â  // Update the global final transcript storage
Â  Â  transcriptText += final;
Â  Â  
Â  Â  // Display both final and live interim text in the div
Â  Â  transcriptDiv.innerText = transcriptText + (interim ? ' (' + interim + '...)' : '');
Â  Â  
Â  Â  // Auto-scroll to the bottom for the live effect
Â  Â  transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
Â  };

Â  // Event fired when recognition ends unexpectedly (e.g., timeout)
Â  recog.onend = () => {
Â  Â  if (listening) {
Â  Â  Â  // If still meant to be listening, restart the service (to handle timeouts)
Â  Â  Â  updateStatus('âš ï¸ Restarting listening service...', '#f39c12');
Â  Â  Â  try {
Â  Â  Â  Â  recog.start();
Â  Â  Â  } catch (e) {
Â  Â  Â  Â  // Catch error if start is called too soon
Â  Â  Â  Â  console.error('Error restarting recognition:', e);
Â  Â  Â  }
Â  Â  }
Â  };
Â  
Â  // Event fired on errors
Â  recog.onerror = (event) => {
Â  Â  updateStatus(`âŒ Recognition Error: ${event.error}`, '#e74c3c');
Â  Â  console.error('Speech recognition error:', event.error);
Â  Â  // Stop the process on critical error
Â  Â  if (listening) {
Â  Â  Â  recognition.stop();
Â  Â  Â  listening = false;
Â  Â  Â  updateButtons(false);
Â  Â  Â  updateStatus('Transcription stopped due to error.', '#e74c3c');
Â  Â  }
Â  };

Â  return recog;
}

// --- Event Listeners ---

startBtn.addEventListener('click', () => {
Â  if (listening) return;

Â  // Clear transcript only if it's the first time or user wants a fresh start (optional, but cleaner)
Â  if (transcriptText.trim().length > 0) {
Â  Â  transcriptText = '';
Â  Â  transcriptDiv.innerText = '';
Â  }
Â  
Â  recognition = initializeRecognition();
Â  
Â  if (recognition) {
Â  Â  try {
Â  Â  Â  recognition.start();
Â  Â  Â  listening = true;
Â  Â  Â  updateButtons(true);
Â  Â  Â  updateStatus('ğŸŸ¢ Listening... Speak now.', '#2ecc71');
Â  Â  } catch (e) {
Â  Â  Â  // Handle case where recognition is already active
Â  Â  Â  console.warn('Recognition already started or an error occurred:', e);
Â  Â  Â  listening = true;
Â  Â  Â  updateButtons(true);
Â  Â  Â  updateStatus('ğŸŸ¢ Listening... Speak now.', '#2ecc71');
Â  Â  }
Â  }
});

stopBtn.addEventListener('click', () => {
Â  if (!listening) return;
Â  
Â  recognition.stop();
Â  listening = false;
Â  updateButtons(false);
Â  updateStatus('â¸ï¸ Recording stopped. Finalizing transcript.', '#3498db');
Â  
Â  // Remove the interim text placeholder after stopping
Â  transcriptDiv.innerText = transcriptText;
});

downloadBtn.addEventListener('click', () => {
Â  if (transcriptText.trim().length === 0) {
Â  Â  updateStatus('ğŸš« Nothing to download.', '#e74c3c');
Â  Â  return;
Â  }
Â  
Â  const blob = new Blob([transcriptText], { type: 'text/plain' });
Â  const url = URL.createObjectURL(blob);
Â  const a = document.createElement('a');
Â  const date = new Date().toISOString().slice(0, 10);
Â  
Â  a.href = url;
Â  a.download = `meeting_transcript_${date}.txt`;
Â  
Â  document.body.appendChild(a);
Â  a.click();
Â  
Â  // Clean up the temporary URL and element
Â  document.body.removeChild(a);
Â  URL.revokeObjectURL(url);
Â  
Â  updateStatus('âœ… Transcript downloaded successfully!', '#2ecc71');
});

// Initial state setup
document.addEventListener('DOMContentLoaded', () => {
Â  updateButtons(false);
});
</script>
</body>
</html>
