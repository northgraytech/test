<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>⚫ NGT Stealth Transcriber - Audio & Text</title>
<style>
/* --- NGT Dark Mode Styling --- (Minimal Changes) */
body { 
    font-family: 'Consolas', 'Courier New', monospace;
    background-color: #121212;
    margin:0; 
    padding:0; 
    text-align:center; 
    color:#e0e0e0;
}
header { 
    background-color:#000; 
    color:#fff; 
    padding:30px; 
    box-shadow: 0 4px 10px rgba(0,0,0,0.5); 
    border-bottom: 3px solid #e63946;
}
header h1 { 
    margin:0; 
    color:#4fc3f7;
    font-size: 2.5em; 
    letter-spacing: 2px;
}
section { 
    padding:30px 20px; 
}
.controls { 
    margin: 30px auto; 
    max-width: 900px; /* Wider to accommodate 4 buttons */
    display: flex; 
    justify-content: space-around; 
    flex-wrap: wrap; /* Ensure buttons wrap if screen is small */
}

/* --- Button Styling --- */
button { 
    padding:12px 20px; 
    margin: 5px; /* Added margin for spacing in the wider container */
    font-size:16px; 
    border: 2px solid;
    border-radius:6px; 
    cursor:pointer; 
    transition: background-color 0.3s, border-color 0.3s, transform 0.1s, box-shadow 0.3s; 
    font-weight: bold; 
    min-width: 180px; 
    letter-spacing: 1px;
    text-transform: uppercase;
}
button:hover { 
    transform: translateY(-2px); 
    box-shadow: 0 0 15px rgba(79, 195, 247, 0.4);
}
button:disabled { 
    opacity: 0.4; 
    cursor: not-allowed; 
    transform: none; 
    box-shadow: none; 
}

#startBtn { 
    background-color:#e63946;
    color:#fff; 
    border-color: #e63946;
}
#startBtn:hover:not(:disabled) { 
    background-color: #c0392b; 
    border-color: #c0392b;
}
#stopBtn { 
    background-color:#2c3e50;
    color:#fff; 
    border-color: #4fc3f7;
}
#stopBtn:hover:not(:disabled) { 
    background-color: #34495e;
}
/* New Button Styles */
#downloadTextBtn { 
    background-color: #1a1a1a; 
    color:#4fc3f7;
    border-color: #4fc3f7;
}
#downloadTextBtn:hover:not(:disabled) { 
    background-color: #4fc3f7; 
    color: #000; 
}
#downloadAudioBtn { 
    background-color: #1a1a1a; 
    color:#00ff00; /* Green accent for audio */
    border-color: #00ff00;
}
#downloadAudioBtn:hover:not(:disabled) { 
    background-color: #00ff00; 
    color: #000; 
}

/* --- Status & Transcript Styling --- */
#status { 
    margin-top: 20px; 
    font-size: 1.1em; 
    color: #4fc3f7; 
    min-height: 20px; 
    text-shadow: 0 0 5px rgba(79, 195, 247, 0.5);
}
#transcript { 
    width:90%; 
    max-width:900px;
    margin:25px auto; 
    padding:20px; 
    border:2px solid #333; 
    min-height:350px; 
    overflow-y:auto; 
    background-color:#1c1c1c;
    color:#00ff00;
    text-align: left; 
    line-height: 1.5; 
    border-radius: 4px; 
    box-shadow: inset 0 0 10px rgba(0,255,0,0.1);
    white-space: pre-wrap;
    font-size: 1.05em;
}
</style>
</head>
<body>
<header>
  <h1>NGT | STEALTH TRANSCRIBER v2.0</h1>
</header>
<section>
  <p>INITIATE live audio capture and transcription for meeting data logging. Click <span style="color:#e63946; font-weight:bold;">START</span> to begin data feed.</p>
  <div class="controls">
    <button id="startBtn">START RECORDING</button>
    <button id="stopBtn" disabled>STOP DATA FEED</button>
    <button id="downloadTextBtn" disabled>DOWNLOAD LOG (Text)</button>
    <button id="downloadAudioBtn" disabled>DOWNLOAD AUDIO (WAV)</button>
  </div>
  <div id="status">STATUS: System Online.</div>
  <div id="transcript"></div>
</section>

<script>
let recognition = null;
let mediaRecorder = null;
let audioChunks = [];
let audioBlob = null;
let listening = false;
let transcriptText = '';
const transcriptDiv = document.getElementById('transcript');
const statusDiv = document.getElementById('status');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const downloadTextBtn = document.getElementById('downloadTextBtn'); // Renamed
const downloadAudioBtn = document.getElementById('downloadAudioBtn'); // New

// --- Helper Functions ---

function updateStatus(message, color = '#4fc3f7') {
  statusDiv.innerText = 'STATUS: ' + message;
  statusDiv.style.color = color;
  statusDiv.style.textShadow = color !== '#e63946' ? `0 0 5px ${color}` : 'none';
}

function updateButtons(isListening) {
  startBtn.disabled = isListening;
  stopBtn.disabled = !isListening;
  downloadTextBtn.disabled = isListening || transcriptText.trim().length === 0;
  downloadAudioBtn.disabled = isListening || audioBlob === null;
}

function handleDownload(blob, filename) {
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
}

// --- Audio Recording Core (MediaStream Recording API) ---

async function startAudioRecording() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream);
    audioChunks = [];

    mediaRecorder.ondataavailable = event => {
      audioChunks.push(event.data);
    };

    mediaRecorder.onstop = () => {
      // Create the audio blob once recording stops
      audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
      // Stop the microphone stream tracks to release the mic
      stream.getTracks().forEach(track => track.stop()); 
      updateButtons(false);
    };
    
    // Start recording audio
    mediaRecorder.start(); 
    return true;

  } catch (err) {
    updateStatus(`MIC ACCESS DENIED: ${err.name}. Check browser permissions.`, '#e63946');
    console.error('Audio recording error:', err);
    return false;
  }
}

function stopAudioRecording() {
  if (mediaRecorder && mediaRecorder.state !== 'inactive') {
    mediaRecorder.stop();
  }
}

// --- Speech Recognition Core (Web Speech API) ---

function initializeRecognition() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

  if (!SpeechRecognition) {
    updateStatus('ERROR: Web Speech API not detected.', '#e63946');
    return null;
  }
  
  // ... (recognition logic is mostly the same as previous version) ...
  const recog = new SpeechRecognition();
  recog.continuous = true; 
  recog.interimResults = true; 
  recog.lang = 'en-US'; 

  recog.onresult = (event) => {
    let interim = '';
    let final = '';

    for (let i = event.resultIndex; i < event.results.length; ++i) {
      const result = event.results[i];
      if (result.isFinal) {
        let sentence = result[0].transcript;
        sentence = sentence.charAt(0).toUpperCase() + sentence.slice(1);
        final += `> ${sentence}. \n`; 
      } else {
        interim += result[0].transcript;
      }
    }

    transcriptText += final;
    
    transcriptDiv.innerText = transcriptText + (interim ? ` [LIVE FEED: ${interim}... ]` : '');
    transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
  };

  recog.onend = () => {
    if (listening) {
      updateStatus('RESTARTING: Service Timeout Detected...', '#e63946');
      try {
        recog.start();
      } catch (e) {
        console.error('Error restarting recognition:', e);
      }
    }
  };
  
  recog.onerror = (event) => {
    updateStatus(`CRITICAL ERROR: ${event.error}. Stopping all processes.`, '#e63946');
    stopAllProcesses();
  };

  return recog;
}

function stopAllProcesses() {
    if (!listening) return;
    
    // Stop Web Speech API
    if (recognition) recognition.stop();
    
    // Stop Media Recorder
    stopAudioRecording();

    listening = false;
    updateButtons(false);
    updateStatus('PAUSED: Finalizing Transcript Log and Audio.', '#4fc3f7');
    transcriptDiv.innerText = transcriptText;
}

// --- Event Listeners ---

startBtn.addEventListener('click', async () => {
  if (listening) return;

  // 1. Clear previous data
  transcriptText = '';
  transcriptDiv.innerText = '';
  audioBlob = null;
  audioChunks = [];

  // 2. Start Audio Recording (must be requested first to get mic permission)
  const audioStarted = await startAudioRecording();
  if (!audioStarted) return; // Stop if mic access failed

  // 3. Start Transcription
  recognition = initializeRecognition();
  
  if (recognition) {
    try {
      recognition.start();
      listening = true;
      updateButtons(true);
      updateStatus('ACTIVE: Data Feed Initiated. Audio and Text Capture Running.', '#00ff00');
    } catch (e) {
      console.warn('Recognition start failed:', e);
      listening = true;
      updateButtons(true);
      updateStatus('ACTIVE: Data Feed Initiated. Audio and Text Capture Running.', '#00ff00');
    }
  }
});

stopBtn.addEventListener('click', stopAllProcesses);

downloadTextBtn.addEventListener('click', () => {
  if (transcriptText.trim().length === 0) {
    updateStatus('ERROR: Log is empty. Nothing to download.', '#e63946');
    return;
  }
  
  const date = new Date().toISOString().slice(0, 19).replace(/[:T-]/g, '');
  const blob = new Blob([transcriptText], { type: 'text/plain' });
  handleDownload(blob, `NGT_LOG_TEXT_${date}.txt`);
  
  updateStatus('SUCCESS: Text Log downloaded.', '#00ff00');
});

downloadAudioBtn.addEventListener('click', () => {
    if (!audioBlob) {
        updateStatus('ERROR: Audio buffer is empty. Nothing to download.', '#e63946');
        return;
    }
  
    const date = new Date().toISOString().slice(0, 19).replace(/[:T-]/g, '');
    // NOTE: The MIME type of the audio blob is determined by the browser/MediaRecorder. 
    // It's often 'audio/webm' or 'audio/ogg', not necessarily WAV, but we can name it generically.
    const fileExtension = audioBlob.type.includes('webm') ? 'webm' : audioBlob.type.includes('ogg') ? 'ogg' : 'wav'; 
    handleDownload(audioBlob, `NGT_LOG_AUDIO_${date}.${fileExtension}`);
  
    updateStatus('SUCCESS: Audio Log downloaded.', '#00ff00');
});

// Initial state setup
document.addEventListener('DOMContentLoaded', () => {
  updateButtons(false);
});
</script>
</body>
</html>
